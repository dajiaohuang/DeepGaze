{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from imageio.v3 import imread, imwrite\n",
    "from PIL import Image\n",
    "import pysaliency\n",
    "from pysaliency.baseline_utils import BaselineModel, CrossvalidatedBaselineModel\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import model_zoo\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from deepgaze_pytorch.layers import (\n",
    "    Conv2dMultiInput,\n",
    "    LayerNorm,\n",
    "    LayerNormMultiInput,\n",
    "    Bias,\n",
    "    FlexibleScanpathHistoryEncoding\n",
    ")\n",
    "\n",
    "from deepgaze_pytorch.modules import DeepGazeIII, FeatureExtractor\n",
    "from deepgaze_pytorch.features.densenet import RGBDenseNet201\n",
    "from deepgaze_pytorch.data import ImageDataset, ImageDatasetSampler, FixationDataset, FixationMaskTransform\n",
    "from deepgaze_pytorch.training import _train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_saliency_network(input_channels):\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        ('layernorm0', LayerNorm(input_channels)),\n",
    "        ('conv0', nn.Conv2d(input_channels, 8, (1, 1), bias=False)),\n",
    "        ('bias0', Bias(8)),\n",
    "        ('softplus0', nn.Softplus()),\n",
    "\n",
    "        ('layernorm1', LayerNorm(8)),\n",
    "        ('conv1', nn.Conv2d(8, 16, (1, 1), bias=False)),\n",
    "        ('bias1', Bias(16)),\n",
    "        ('softplus1', nn.Softplus()),\n",
    "\n",
    "        ('layernorm2', LayerNorm(16)),\n",
    "        ('conv2', nn.Conv2d(16, 1, (1, 1), bias=False)),\n",
    "        ('bias2', Bias(1)),\n",
    "        ('softplus2', nn.Softplus()),\n",
    "    ]))\n",
    "\n",
    "\n",
    "def build_scanpath_network():\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        ('encoding0', FlexibleScanpathHistoryEncoding(in_fixations=4, channels_per_fixation=3, out_channels=128, kernel_size=[1, 1], bias=True)),\n",
    "        ('softplus0', nn.Softplus()),\n",
    "\n",
    "        ('layernorm1', LayerNorm(128)),\n",
    "        ('conv1', nn.Conv2d(128, 16, (1, 1), bias=False)),\n",
    "        ('bias1', Bias(16)),\n",
    "        ('softplus1', nn.Softplus()),\n",
    "    ]))\n",
    "\n",
    "\n",
    "def build_fixation_selection_network(scanpath_features=16):\n",
    "    return nn.Sequential(OrderedDict([\n",
    "        ('layernorm0', LayerNormMultiInput([1, scanpath_features])),\n",
    "        ('conv0', Conv2dMultiInput([1, scanpath_features], 128, (1, 1), bias=False)),\n",
    "        ('bias0', Bias(128)),\n",
    "        ('softplus0', nn.Softplus()),\n",
    "\n",
    "        ('layernorm1', LayerNorm(128)),\n",
    "        ('conv1', nn.Conv2d(128, 16, (1, 1), bias=False)),\n",
    "        ('bias1', Bias(16)),\n",
    "        ('softplus1', nn.Softplus()),\n",
    "\n",
    "        ('conv2', nn.Conv2d(16, 1, (1, 1), bias=False)),\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_spatial_dataset(stimuli, fixations, centerbias, batch_size, path=None):\n",
    "    if path is not None:\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        lmdb_path = str(path)\n",
    "    else:\n",
    "        lmdb_path = None\n",
    "\n",
    "    dataset = ImageDataset(\n",
    "        stimuli=stimuli,\n",
    "        fixations=fixations,\n",
    "        centerbias_model=centerbias,\n",
    "        transform=FixationMaskTransform(sparse=False),\n",
    "        average='image',\n",
    "        lmdb_path=lmdb_path,\n",
    "    )\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_sampler=ImageDatasetSampler(dataset, batch_size=batch_size),\n",
    "        pin_memory=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_scanpath_dataset(stimuli, fixations, centerbias, batch_size, path=None):\n",
    "    if path is not None:\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        lmdb_path = str(path)\n",
    "    else:\n",
    "        lmdb_path = None\n",
    "\n",
    "    dataset = FixationDataset(\n",
    "        stimuli=stimuli,\n",
    "        fixations=fixations,\n",
    "        centerbias_model=centerbias,\n",
    "        included_fixations=[-1, -2, -3, -4],\n",
    "        allow_missing_fixations=True,\n",
    "        transform=FixationMaskTransform(sparse=False),\n",
    "        average='image',\n",
    "        lmdb_path=lmdb_path,\n",
    "    )\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_sampler=ImageDatasetSampler(dataset, batch_size=batch_size),\n",
    "        pin_memory=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('pysaliency_datasets')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_directory = Path('pysaliency_datasets')\n",
    "dataset_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('train_deepgaze3')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_directory = Path('train_deepgaze3')\n",
    "train_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining on SALICON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/10000 [00:03<1:53:24,  1.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m SALICON_centerbias \u001b[39m=\u001b[39m BaselineModel(stimuli\u001b[39m=\u001b[39mSALICON_train_stimuli, fixations\u001b[39m=\u001b[39mSALICON_train_fixations, bandwidth\u001b[39m=\u001b[39m\u001b[39m0.0217\u001b[39m, eps\u001b[39m=\u001b[39m\u001b[39m2e-13\u001b[39m, caching\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# takes quite some time, feel free to set to zero\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_baseline_log_likelihood \u001b[39m=\u001b[39m SALICON_centerbias\u001b[39m.\u001b[39minformation_gain(SALICON_train_stimuli, SALICON_train_fixations, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m val_baseline_log_likelihood \u001b[39m=\u001b[39m SALICON_centerbias\u001b[39m.\u001b[39minformation_gain(SALICON_val_stimuli, SALICON_val_fixations, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mf:\\anaconda3\\Lib\\site-packages\\pysaliency\\models.py:144\u001b[0m, in \u001b[0;36mScanpathModel.information_gain\u001b[1;34m(self, stimuli, fixations, baseline_model, verbose, average)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minformation_gain\u001b[39m(\u001b[39mself\u001b[39m, stimuli, fixations, baseline_model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfixation\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m average_values(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minformation_gains(stimuli, fixations, baseline_model, verbose\u001b[39m=\u001b[39mverbose), fixations, average\u001b[39m=\u001b[39maverage)\n",
      "File \u001b[1;32mf:\\anaconda3\\Lib\\site-packages\\pysaliency\\models.py:139\u001b[0m, in \u001b[0;36mScanpathModel.information_gains\u001b[1;34m(self, stimuli, fixations, baseline_model, verbose, average)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m baseline_model \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     baseline_model \u001b[39m=\u001b[39m UniformModel()\n\u001b[1;32m--> 139\u001b[0m own_log_likelihoods \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_likelihoods(stimuli, fixations, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m    140\u001b[0m baseline_log_likelihoods \u001b[39m=\u001b[39m baseline_model\u001b[39m.\u001b[39mlog_likelihoods(stimuli, fixations, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m    141\u001b[0m \u001b[39mreturn\u001b[39;00m (own_log_likelihoods \u001b[39m-\u001b[39m baseline_log_likelihoods) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mf:\\anaconda3\\Lib\\site-packages\\pysaliency\\models.py:300\u001b[0m, in \u001b[0;36mModel.log_likelihoods\u001b[1;34m(self, stimuli, fixations, verbose)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(stimuli)), disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m verbose):\n\u001b[0;32m    299\u001b[0m     inds \u001b[39m=\u001b[39m fixations\u001b[39m.\u001b[39mn \u001b[39m==\u001b[39m n\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inds\u001b[39m.\u001b[39msum():\n\u001b[0;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     log_density \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_density(stimuli\u001b[39m.\u001b[39mstimulus_objects[n])\n",
      "File \u001b[1;32mf:\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SALICON_train_stimuli, SALICON_train_fixations = pysaliency.get_SALICON_train(location=dataset_directory)\n",
    "SALICON_val_stimuli, SALICON_val_fixations = pysaliency.get_SALICON_val(location=dataset_directory)\n",
    "\n",
    "# parameters taken from an early fit for MIT1003. Since SALICON has many more fixations, the bandwidth won't be too small\n",
    "SALICON_centerbias = BaselineModel(stimuli=SALICON_train_stimuli, fixations=SALICON_train_fixations, bandwidth=0.0217, eps=2e-13, caching=False)\n",
    "\n",
    "# takes quite some time, feel free to set to zero\n",
    "train_baseline_log_likelihood = SALICON_centerbias.information_gain(SALICON_train_stimuli, SALICON_train_fixations, verbose=True, average='image')\n",
    "val_baseline_log_likelihood = SALICON_centerbias.information_gain(SALICON_val_stimuli, SALICON_val_fixations, verbose=True, average='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Administrator/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "model = DeepGazeIII(\n",
    "    features=FeatureExtractor(RGBDenseNet201(), [\n",
    "            '1.features.denseblock4.denselayer32.norm1',\n",
    "            '1.features.denseblock4.denselayer32.conv1',\n",
    "            '1.features.denseblock4.denselayer31.conv2',\n",
    "        ]),\n",
    "    saliency_network=build_saliency_network(2048),\n",
    "    scanpath_network=None,\n",
    "    fixation_selection_network=build_fixation_selection_network(scanpath_features=0),\n",
    "    downsample=1.5,\n",
    "    readout_factor=4,\n",
    "    saliency_map_factor=4,\n",
    "    included_fixations=[],\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 30, 45, 60, 75, 90, 105, 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate LMDB to train_deepgaze3\\lmdb_cache\\SALICON_train\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "train_deepgaze3\\lmdb_cache\\SALICON_train: ���̿ռ䲻�㡣\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_loader \u001b[39m=\u001b[39m prepare_spatial_dataset(SALICON_train_stimuli, SALICON_train_fixations, SALICON_centerbias, batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, path\u001b[39m=\u001b[39mtrain_directory \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlmdb_cache\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSALICON_train\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m validation_loader \u001b[39m=\u001b[39m prepare_spatial_dataset(SALICON_val_stimuli, SALICON_val_fixations, SALICON_centerbias, batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, path\u001b[39m=\u001b[39mtrain_directory \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlmdb_cache\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSALICON_val\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 8\u001b[0m, in \u001b[0;36mprepare_spatial_dataset\u001b[1;34m(stimuli, fixations, centerbias, batch_size, path)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     lmdb_path \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m dataset \u001b[39m=\u001b[39m ImageDataset(\n\u001b[0;32m      9\u001b[0m     stimuli\u001b[39m=\u001b[39mstimuli,\n\u001b[0;32m     10\u001b[0m     fixations\u001b[39m=\u001b[39mfixations,\n\u001b[0;32m     11\u001b[0m     centerbias_model\u001b[39m=\u001b[39mcenterbias,\n\u001b[0;32m     12\u001b[0m     transform\u001b[39m=\u001b[39mFixationMaskTransform(sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[0;32m     13\u001b[0m     average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     lmdb_path\u001b[39m=\u001b[39mlmdb_path,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[0;32m     18\u001b[0m     dataset,\n\u001b[0;32m     19\u001b[0m     batch_sampler\u001b[39m=\u001b[39mImageDatasetSampler(dataset, batch_size\u001b[39m=\u001b[39mbatch_size),\n\u001b[0;32m     20\u001b[0m     pin_memory\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m loader\n",
      "File \u001b[1;32mf:\\cs3324\\DeepGaze\\deepgaze_pytorch\\data.py:69\u001b[0m, in \u001b[0;36mImageDataset.__init__\u001b[1;34m(self, stimuli, fixations, centerbias_model, lmdb_path, transform, cached, average)\u001b[0m\n\u001b[0;32m     66\u001b[0m cache_fixation_data \u001b[39m=\u001b[39m cached\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m lmdb_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     _export_dataset_to_lmdb(stimuli, centerbias_model, lmdb_path)\n\u001b[0;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlmdb_env \u001b[39m=\u001b[39m lmdb\u001b[39m.\u001b[39mopen(lmdb_path, subdir\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(lmdb_path),\n\u001b[0;32m     71\u001b[0m         readonly\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lock\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m         readahead\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, meminit\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     )\n\u001b[0;32m     74\u001b[0m     cached \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mf:\\cs3324\\DeepGaze\\deepgaze_pytorch\\data.py:341\u001b[0m, in \u001b[0;36m_export_dataset_to_lmdb\u001b[1;34m(stimuli, centerbias_model, lmdb_path, write_frequency)\u001b[0m\n\u001b[0;32m    338\u001b[0m isdir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(lmdb_path)\n\u001b[0;32m    340\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mGenerate LMDB to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m lmdb_path)\n\u001b[1;32m--> 341\u001b[0m db \u001b[39m=\u001b[39m lmdb\u001b[39m.\u001b[39mopen(lmdb_path, subdir\u001b[39m=\u001b[39misdir,\n\u001b[0;32m    342\u001b[0m                map_size\u001b[39m=\u001b[39m\u001b[39m1099511627776\u001b[39m \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, readonly\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    343\u001b[0m                meminit\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, map_async\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    345\u001b[0m txn \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mbegin(write\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    346\u001b[0m \u001b[39mfor\u001b[39;00m idx, stimulus \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(stimuli)):\n",
      "\u001b[1;31mError\u001b[0m: train_deepgaze3\\lmdb_cache\\SALICON_train: ���̿ռ䲻�㡣\r\n"
     ]
    }
   ],
   "source": [
    "train_loader = prepare_spatial_dataset(SALICON_train_stimuli, SALICON_train_fixations, SALICON_centerbias, batch_size=4, path=train_directory / 'lmdb_cache' / 'SALICON_train')\n",
    "validation_loader = prepare_spatial_dataset(SALICON_val_stimuli, SALICON_val_fixations, SALICON_centerbias, batch_size=4, path=train_directory / 'lmdb_cache' / 'SALICON_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m _train(train_directory \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpretraining\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m     model,\n\u001b[1;32m----> 3\u001b[0m     train_loader, train_baseline_log_likelihood,\n\u001b[0;32m      4\u001b[0m     validation_loader, val_baseline_log_likelihood,\n\u001b[0;32m      5\u001b[0m     optimizer, lr_scheduler,\n\u001b[0;32m      6\u001b[0m     minimum_learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m,\n\u001b[0;32m      7\u001b[0m     device\u001b[39m=\u001b[39mdevice,\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "_train(train_directory / 'pretraining',\n",
    "    model,\n",
    "    train_loader, train_baseline_log_likelihood,\n",
    "    validation_loader, val_baseline_log_likelihood,\n",
    "    optimizer, lr_scheduler,\n",
    "    minimum_learning_rate=1e-7,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the MIT1003 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_mit1003_with_initial_fixation() got an unexpected keyword argument 'replace_initial_invalid_fixations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mit_stimuli_orig, mit_scanpaths_orig \u001b[39m=\u001b[39m pysaliency\u001b[39m.\u001b[39mexternal_datasets\u001b[39m.\u001b[39mmit\u001b[39m.\u001b[39mget_mit1003_with_initial_fixation(location\u001b[39m=\u001b[39mdataset_directory, replace_initial_invalid_fixations\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: get_mit1003_with_initial_fixation() got an unexpected keyword argument 'replace_initial_invalid_fixations'"
     ]
    }
   ],
   "source": [
    "mit_stimuli_orig, mit_scanpaths_orig = pysaliency.external_datasets.mit.get_mit1003_with_initial_fixation(location=dataset_directory, replace_initial_invalid_fixations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15045/15045 [00:00<00:00, 214631.98it/s]\n",
      "100%|██████████| 1003/1003 [01:10<00:00, 14.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_stimulus(input_image):\n",
    "    size = input_image.shape[0], input_image.shape[1]\n",
    "    if size[0] < size[1]:\n",
    "        new_size = 768, 1024\n",
    "    else:\n",
    "        new_size = 1024,768\n",
    "    \n",
    "    # pillow uses width, height\n",
    "    new_size = tuple(list(new_size)[::-1])\n",
    "    \n",
    "    new_stimulus = np.array(Image.fromarray(input_image).resize(new_size, Image.BILINEAR))\n",
    "    return new_stimulus\n",
    "\n",
    "def convert_fixations(stimuli, fixations):\n",
    "    new_fixations = fixations.copy()\n",
    "    for n in tqdm(list(range(len(stimuli)))):\n",
    "        stimulus = stimuli.stimuli[n]\n",
    "        size = stimulus.shape[0], stimulus.shape[1]\n",
    "        if size[0] < size[1]:\n",
    "            new_size = 768, 1024\n",
    "        else:\n",
    "            new_size = 1024,768\n",
    "        x_factor = new_size[1] / size[1]\n",
    "        y_factor = new_size[0] / size[0]\n",
    "        \n",
    "        inds = new_fixations.n == n\n",
    "        new_fixations.x[inds] *= x_factor\n",
    "        new_fixations.y[inds] *= y_factor\n",
    "        new_fixations.x_hist[inds] *= x_factor\n",
    "        new_fixations.y_hist[inds] *= y_factor\n",
    "    \n",
    "    return new_fixations\n",
    "\n",
    "def convert_fixation_trains(stimuli, fixations):\n",
    "    train_xs = fixations.train_xs.copy()\n",
    "    train_ys = fixations.train_ys.copy()\n",
    "    \n",
    "    for i in tqdm(range(len(train_xs))):\n",
    "        n = fixations.train_ns[i]\n",
    "        \n",
    "        size = stimuli.shapes[n][0], stimuli.shapes[n][1]\n",
    "        \n",
    "        if size[0] < size[1]:\n",
    "            new_size = 768, 1024\n",
    "        else:\n",
    "            new_size = 1024,768\n",
    "        \n",
    "        x_factor = new_size[1] / size[1]\n",
    "        y_factor = new_size[0] / size[0]\n",
    "        \n",
    "        train_xs[i] *= x_factor\n",
    "        train_ys[i] *= y_factor\n",
    "        \n",
    "    new_fixations = pysaliency.FixationTrains(\n",
    "        train_xs = train_xs,\n",
    "        train_ys = train_ys,\n",
    "        train_ts = fixations.train_ts.copy(),\n",
    "        train_ns = fixations.train_ns.copy(),\n",
    "        train_subjects = fixations.train_subjects.copy(),\n",
    "        attributes={key: getattr(fixations, key).copy() for key in fixations.__attributes__ if key not in ['subjects', 'scanpath_index']},\n",
    "    )\n",
    "    return new_fixations\n",
    "\n",
    "\n",
    "\n",
    "def convert_stimuli(stimuli, new_location: Path):\n",
    "    assert isinstance(stimuli, pysaliency.FileStimuli)\n",
    "    new_stimuli_location = new_location / 'stimuli'\n",
    "    new_stimuli_location.mkdir(parents=True, exist_ok=True)\n",
    "    new_filenames = []\n",
    "    for filename in tqdm(stimuli.filenames):\n",
    "        stimulus = imread(filename)\n",
    "        new_stimulus = convert_stimulus(stimulus)\n",
    "        \n",
    "        basename = os.path.basename(filename)\n",
    "        new_filename = new_stimuli_location / basename\n",
    "        if new_stimulus.size != stimulus.size:\n",
    "            imwrite(new_filename, new_stimulus)\n",
    "        else:\n",
    "            #print(\"Keeping\")\n",
    "            shutil.copy(filename, new_filename)\n",
    "        new_filenames.append(new_filename)\n",
    "    return pysaliency.FileStimuli(new_filenames)\n",
    "\n",
    "mit_scanpaths_twosize = convert_fixation_trains(mit_stimuli_orig, mit_scanpaths_orig)\n",
    "mit_stimuli_twosize = convert_stimuli(mit_stimuli_orig, train_directory / 'MIT1003_twosize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mit_scanpaths_twosize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# remove the initial forced fixation from the training data, it's only used for conditioning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mit_fixations_twosize \u001b[39m=\u001b[39m mit_scanpaths_twosize[mit_scanpaths_twosize\u001b[39m.\u001b[39mlengths \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mit_scanpaths_twosize' is not defined"
     ]
    }
   ],
   "source": [
    "# remove the initial forced fixation from the training data, it's only used for conditioning\n",
    "mit_fixations_twosize = mit_scanpaths_twosize[mit_scanpaths_twosize.lengths > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters optimized on MIT1003 for maximum leave-one-image-out crossvalidation log-likelihood\n",
    "MIT1003_centerbias = CrossvalidatedBaselineModel(\n",
    "    mit_stimuli_twosize,\n",
    "    mit_fixations_twosize,\n",
    "    bandwidth=10**-1.6667673342543432,\n",
    "    eps=10**-14.884189168516073,\n",
    "    caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random shuffles for crossvalidation\n",
      "Using random shuffles for crossvalidation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808/808 [02:11<00:00,  6.15it/s]\n",
      "100%|██████████| 94/94 [00:13<00:00,  6.89it/s]\n",
      "Using cache found in /home/bethge/mkuemmerer31/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "/opt/conda/envs/deepgaze3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/deepgaze3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "for crossval_fold in range(10):\n",
    "    MIT1003_stimuli_train, MIT1003_fixations_train = pysaliency.dataset_config.train_split(mit_stimuli_twosize, mit_fixations_twosize, crossval_folds=10, fold_no=crossval_fold)\n",
    "    MIT1003_stimuli_val, MIT1003_fixations_val = pysaliency.dataset_config.validation_split(mit_stimuli_twosize, mit_fixations_twosize, crossval_folds=10, fold_no=crossval_fold)\n",
    "\n",
    "    train_baseline_log_likelihood = MIT1003_centerbias.information_gain(MIT1003_stimuli_train, MIT1003_fixations_train, verbose=True, average='image')\n",
    "    val_baseline_log_likelihood = MIT1003_centerbias.information_gain(MIT1003_stimuli_val, MIT1003_fixations_val, verbose=True, average='image')\n",
    "\n",
    "    # finetune spatial model on MIT1003\n",
    "\n",
    "    model = DeepGazeIII(\n",
    "        features=FeatureExtractor(RGBDenseNet201(), [\n",
    "                '1.features.denseblock4.denselayer32.norm1',\n",
    "                '1.features.denseblock4.denselayer32.conv1',\n",
    "                '1.features.denseblock4.denselayer31.conv2',\n",
    "            ]),\n",
    "        saliency_network=build_saliency_network(2048),\n",
    "        scanpath_network=None,\n",
    "        fixation_selection_network=build_fixation_selection_network(scanpath_features=0),\n",
    "        downsample=2,\n",
    "        readout_factor=4,\n",
    "        saliency_map_factor=4,\n",
    "        included_fixations=[],\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "    train_loader = prepare_spatial_dataset(MIT1003_stimuli_train, MIT1003_fixations_train, MIT1003_centerbias, batch_size=4, path=train_directory / 'lmdb_cache' / f'MIT1003_train_spatial_{crossval_fold}')\n",
    "    validation_loader = prepare_spatial_dataset(MIT1003_stimuli_val, MIT1003_fixations_val, MIT1003_centerbias, batch_size=4, path=train_directory / 'lmdb_cache' / f'MIT1003_val_spatial_{crossval_fold}')\n",
    "\n",
    "    _train(train_directory / 'MIT1003_spatial' / f'crossval-10-{crossval_fold}',\n",
    "        model,\n",
    "        train_loader, train_baseline_log_likelihood,\n",
    "        validation_loader, val_baseline_log_likelihood,\n",
    "        optimizer, lr_scheduler,\n",
    "        minimum_learning_rate=1e-7,\n",
    "        device=device,\n",
    "        startwith=train_directory / 'pretraining' / 'final.pth',\n",
    "    )\n",
    "\n",
    "\n",
    "    # Train scanpath model\n",
    "\n",
    "    train_loader = prepare_scanpath_dataset(MIT1003_stimuli_train, MIT1003_fixations_train, MIT1003_centerbias, batch_size=4, path=train_directory / 'lmdb_cache' / f'MIT1003_train_scanpath_{crossval_fold}')\n",
    "    validation_loader = prepare_scanpath_dataset(MIT1003_stimuli_val, MIT1003_fixations_val, MIT1003_centerbias, batch_size=4, path=train_directory / 'lmdb_cache' / f'MIT1003_val_scanpath_{crossval_fold}')\n",
    "\n",
    "    # first train with partially frozen saliency network\n",
    "\n",
    "\n",
    "    model = DeepGazeIII(\n",
    "        features=FeatureExtractor(RGBDenseNet201(), [\n",
    "                '1.features.denseblock4.denselayer32.norm1',\n",
    "                '1.features.denseblock4.denselayer32.conv1',\n",
    "                '1.features.denseblock4.denselayer31.conv2',\n",
    "            ]),\n",
    "        saliency_network=build_saliency_network(2048),\n",
    "        scanpath_network=build_scanpath_network(),\n",
    "        fixation_selection_network=build_fixation_selection_network(scanpath_features=16),\n",
    "        downsample=2,\n",
    "        readout_factor=4,\n",
    "        saliency_map_factor=4,\n",
    "        included_fixations=[-1, -2, -3, -4],\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    frozen_scopes = [\n",
    "        \"saliency_network.layernorm0\",\n",
    "        \"saliency_network.conv0\",\n",
    "        \"saliency_network.bias0\",\n",
    "        \"saliency_network.layernorm1\",\n",
    "        \"saliency_network.conv1\",\n",
    "        \"saliency_network.bias1\",\n",
    "    ]\n",
    "\n",
    "    for scope in frozen_scopes:\n",
    "        for parameter_name, parameter in model.named_parameters():\n",
    "            if parameter_name.startswith(scope):\n",
    "                print(\"Fixating parameter\", parameter_name)\n",
    "                parameter.requires_grad = False\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30, 31, 32, 33, 34, 35])\n",
    "\n",
    "    _train(train_directory / 'MIT1003_scanpath_partially_frozen_saliency_network' / f'crossval-10-{crossval_fold}',\n",
    "        model,\n",
    "        train_loader, train_baseline_log_likelihood,\n",
    "        validation_loader, val_baseline_log_likelihood,\n",
    "        optimizer, lr_scheduler,\n",
    "        minimum_learning_rate=1e-7,\n",
    "        device=device,\n",
    "        startwith=train_directory / 'MIT1003_spatial' /  f'crossval-10-{crossval_fold}' / 'final.pth'\n",
    "    )\n",
    "\n",
    "    # Now finetune full scanpath model\n",
    "\n",
    "    model = DeepGazeIII(\n",
    "        features=FeatureExtractor(RGBDenseNet201(), [\n",
    "                '1.features.denseblock4.denselayer32.norm1',\n",
    "                '1.features.denseblock4.denselayer32.conv1',\n",
    "                '1.features.denseblock4.denselayer31.conv2',\n",
    "            ]),\n",
    "        saliency_network=build_saliency_network(2048),\n",
    "        scanpath_network=build_scanpath_network(),\n",
    "        fixation_selection_network=build_fixation_selection_network(scanpath_features=16),\n",
    "        downsample=2,\n",
    "        readout_factor=4,\n",
    "        saliency_map_factor=4,\n",
    "        included_fixations=[-1, -2, -3, -4],\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3, 6, 9, 12, 15, 18, 21, 24])\n",
    "\n",
    "    _train(train_directory / 'MIT1003_scanpath' / f'crossval-10-{crossval_fold}',\n",
    "        model,\n",
    "        train_loader, train_baseline_log_likelihood,\n",
    "        validation_loader, val_baseline_log_likelihood,\n",
    "        optimizer, lr_scheduler,\n",
    "        minimum_learning_rate=1e-7,\n",
    "        device=device,\n",
    "        startwith=train_directory / 'MIT1003_scanpath_partially_frozen_saliency_network' / f'crossval-10-{crossval_fold}' / 'final.pth'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4df7a6600e22bae99e6e8f837be5af686fd7a404512ca9c2620376f38fe7d31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
